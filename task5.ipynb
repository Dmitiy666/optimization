{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# УСТАНОВКА И ИМПОРТ"
      ],
      "metadata": {
        "id": "Uktgzhy6yVi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install torch torchvision\n",
        "!pip install ultralytics\n",
        "!pip install tqdm\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCVR05qQegYK",
        "outputId": "0e42b82a-a2cb-42dc-845e-72bd72d36e49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.59)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# СКАЧИВАНИЕ И РАСПАКОВКА АРХИВА ДЛЯ ТЕСТОВ"
      ],
      "metadata": {
        "id": "VO65QQqUyiBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "dataset_dir = 'MOT17'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# Ссылка на датасет\n",
        "mot17_url = 'https://motchallenge.net/data/MOT17.zip'\n",
        "zip_path = os.path.join(dataset_dir, 'MOT17.zip')\n",
        "\n",
        "print(\"Скачиваем MOT17 (может занять время)...\")\n",
        "urllib.request.urlretrieve(mot17_url, zip_path)\n",
        "print(\"Скачивание завершено.\")\n",
        "\n",
        "print(\"Распаковка...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_dir)\n",
        "\n",
        "os.remove(zip_path)\n",
        "print(\"Готово! Датасет распакован в папке:\", dataset_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfhCtx76xBph",
        "outputId": "a34951dd-e2cb-48f3-d0e9-59fa3d7d24f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скачиваем MOT17 (может занять время)...\n",
            "Скачивание завершено.\n",
            "Распаковка...\n",
            "Готово! Датасет распакован в папке: MOT17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ФУНКЦИИ ЧТЕНИЯ SEQINFO.INI И GT (GROUND TRUTH)"
      ],
      "metadata": {
        "id": "NuXkVdFjyaJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_seqinfo(seq_dir):\n",
        "    \"\"\"\n",
        "    Считываем seqinfo.ini в dict:\n",
        "    {\n",
        "      'name': ...,\n",
        "      'imDir': ...,\n",
        "      'frameRate': ...,\n",
        "      'seqLength': ...,\n",
        "      'imWidth': ...,\n",
        "      'imHeight': ...,\n",
        "      'imExt': ...\n",
        "    }\n",
        "    \"\"\"\n",
        "    seqinfo_path = os.path.join(seq_dir, \"seqinfo.ini\")\n",
        "    info = {}\n",
        "    if not os.path.exists(seqinfo_path):\n",
        "        print(\"WARNING: seqinfo.ini не найден в\", seq_dir)\n",
        "        return info\n",
        "    with open(seqinfo_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if '=' in line:\n",
        "                key, val = line.split('=', 1)\n",
        "                key, val = key.strip(), val.strip()\n",
        "                info[key] = val\n",
        "    return info\n",
        "\n",
        "def read_ground_truth(gt_path):\n",
        "    \"\"\"\n",
        "    Читаем файл GT (gt.txt). Возвращаем dict:\n",
        "      ground_truth[frame_id] = [(x1,y1,x2,y2,cls=1), ...]\n",
        "    Учитываем только объекты с class=1 (person).\n",
        "    \"\"\"\n",
        "    annotations = {}\n",
        "\n",
        "    with open(gt_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"#\"):\n",
        "                continue\n",
        "            cols = line.split(',')\n",
        "            # формат: frame, id, x, y, w, h, conf, class, visibility\n",
        "            frame_id = int(cols[0])\n",
        "            x = float(cols[2])\n",
        "            y = float(cols[3])\n",
        "            w = float(cols[4])\n",
        "            h = float(cols[5])\n",
        "            conf = float(cols[6])\n",
        "            cls  = int(cols[7])  # класс\n",
        "\n",
        "            # Считаем, что интересует только class=1 => person\n",
        "            if cls != 1:\n",
        "                continue\n",
        "\n",
        "            # Формируем (x1, y1, x2, y2, cls)\n",
        "            x1, y1 = x, y\n",
        "            x2, y2 = x + w, y + h\n",
        "\n",
        "            if frame_id not in annotations:\n",
        "                annotations[frame_id] = []\n",
        "            annotations[frame_id].append((x1, y1, x2, y2, cls))\n",
        "    return annotations\n"
      ],
      "metadata": {
        "id": "nYOQZPS6ej5h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# МЕТРИКИ (IOU, PRECISION, RECALL, F1)"
      ],
      "metadata": {
        "id": "nJMcQpiAyy1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(boxA, boxB):\n",
        "    \"\"\"\n",
        "    boxA, boxB: (x1, y1, x2, y2, ...)\n",
        "    Возвращаем IoU [0..1].\n",
        "    \"\"\"\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interW = max(0, xB - xA)\n",
        "    interH = max(0, yB - yA)\n",
        "    interArea = interW * interH\n",
        "\n",
        "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    unionArea = areaA + areaB - interArea\n",
        "    if unionArea <= 0:\n",
        "        return 0\n",
        "    return interArea / unionArea\n",
        "\n",
        "def match_detections_to_gt(pred_boxes, gt_boxes, iou_thresh=0.5):\n",
        "    \"\"\"\n",
        "    pred_boxes: [(x1, y1, x2, y2, conf, cls), ...]\n",
        "    gt_boxes:   [(x1, y1, x2, y2, cls), ...]\n",
        "    Считаем TP, FP, FN при IoU>=iou_thresh.\n",
        "    \"\"\"\n",
        "    matched_gt = set()\n",
        "    tp = 0\n",
        "    for pb in pred_boxes:\n",
        "        p_box = pb[:4]  # (x1,y1,x2,y2)\n",
        "        found_match = False\n",
        "        for i, gb in enumerate(gt_boxes):\n",
        "            if i in matched_gt:\n",
        "                continue\n",
        "            g_box = gb[:4]\n",
        "            iou = compute_iou(p_box, g_box)\n",
        "            if iou >= iou_thresh:\n",
        "                tp += 1\n",
        "                matched_gt.add(i)\n",
        "                found_match = True\n",
        "                break\n",
        "    fp = len(pred_boxes) - tp\n",
        "    fn = len(gt_boxes) - len(matched_gt)\n",
        "    return tp, fp, fn\n",
        "\n",
        "def compute_metrics(all_preds, all_gts, iou_thresh=0.5):\n",
        "    \"\"\"\n",
        "    all_preds[frame_id] = [(x1,y1,x2,y2,conf,cls), ...]\n",
        "    all_gts[frame_id]   = [(x1,y1,x2,y2,cls), ...]\n",
        "    Возвращаем словарь с Precision, Recall, F1.\n",
        "    \"\"\"\n",
        "    total_tp, total_fp, total_fn = 0, 0, 0\n",
        "    frame_ids = sorted(set(all_preds.keys()).union(all_gts.keys()))\n",
        "    for fid in frame_ids:\n",
        "        preds_f = all_preds.get(fid, [])\n",
        "        gts_f   = all_gts.get(fid, [])\n",
        "        tp, fp, fn = match_detections_to_gt(preds_f, gts_f, iou_thresh)\n",
        "        total_tp += tp\n",
        "        total_fp += fp\n",
        "        total_fn += fn\n",
        "\n",
        "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp)>0 else 0\n",
        "    recall    = total_tp / (total_tp + total_fn) if (total_tp + total_fn)>0 else 0\n",
        "    f1        = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "qiB52XzWessr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ЗАГРУЗКА 3 МОДЕЛЕЙ"
      ],
      "metadata": {
        "id": "-rGfIM2Py3-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "yolov10_weights = \"yolov10n.pt\"\n",
        "yolov11_weights = \"yolo11n.pt\"\n",
        "\n",
        "model_y10 = YOLO(yolov10_weights)\n",
        "model_y11 = YOLO(yolov11_weights)\n",
        "model_y10.to(device)\n",
        "model_y11.to(device)\n",
        "\n",
        "import torchvision.models.detection as models\n",
        "model_ssd = models.ssd300_vgg16(pretrained=True)\n",
        "model_ssd.eval()\n",
        "model_ssd.to(device)\n",
        "\n",
        "print(\"Модели загружены.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_d35fmzez2E",
        "outputId": "e52da879-ee69-4eee-ed03-827f90a6f654"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.59M/5.59M [00:00<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 124MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
            "100%|██████████| 136M/136M [00:05<00:00, 27.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модели загружены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ФУНКЦИИ ДЛЯ ДЕТЕКЦИИ НА ОДНОМ КАДРЕ"
      ],
      "metadata": {
        "id": "bPvwutavzBXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_yolo(model, frame_bgr, device=\"cpu\", conf_thr=0.3, person_class=0):\n",
        "    \"\"\"\n",
        "    Запуск YOLO (v10 или v11) на кадре.\n",
        "    Возвращаем список [(x1,y1,x2,y2,conf,cls), ...], только для class=person_class.\n",
        "    \"\"\"\n",
        "    results = model(frame_bgr, device=device, verbose=False)\n",
        "    dets = []\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "            conf = box.conf.item()\n",
        "            cls  = int(box.cls.item())\n",
        "            if conf >= conf_thr and cls == person_class:\n",
        "                dets.append((x1, y1, x2, y2, conf, cls))\n",
        "    return dets\n",
        "\n",
        "def detect_ssd(model, frame_bgr, device=\"cpu\", conf_thr=0.3, person_class=1):\n",
        "    \"\"\"\n",
        "    Запуск SSD на кадре.\n",
        "    Возвращаем список [(x1,y1,x2,y2,conf,cls), ...], только для class=person_class (COCO = 1).\n",
        "    \"\"\"\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    inp = transform(frame_bgr).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(inp)[0]\n",
        "\n",
        "    dets = []\n",
        "    boxes = out['boxes'].cpu().numpy()\n",
        "    scores = out['scores'].cpu().numpy()\n",
        "    labels = out['labels'].cpu().numpy()\n",
        "    for i in range(len(boxes)):\n",
        "        x1, y1, x2, y2 = boxes[i]\n",
        "        conf = scores[i]\n",
        "        cls  = labels[i]\n",
        "        if conf >= conf_thr and cls == person_class:\n",
        "            dets.append((x1, y1, x2, y2, conf, cls))\n",
        "    return dets\n",
        "\n",
        "# === Настройка классов person для YOLO/SSD ===\n",
        "\n",
        "yolo_person_cls = 0   # для YOLO\n",
        "ssd_person_cls  = 1   # для SSD\n"
      ],
      "metadata": {
        "id": "OXqjtmU2e3d2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ОБРАБОТКА ОДНОЙ ПОСЛЕДОВАТЕЛЬНОСТИ, 3 ОТДЕЛЬНЫХ ВИДЕО"
      ],
      "metadata": {
        "id": "yEERSN00zZkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes_on_frame(frame, dets, color=(0,255,0), thickness=2):\n",
        "    \"\"\"\n",
        "    Рисует bounding boxes (x1,y1,x2,y2,conf,cls) на frame (in-place).\n",
        "    \"\"\"\n",
        "    for (x1,y1,x2,y2,cf,cl) in dets:\n",
        "        cv2.rectangle(frame, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
        "        cv2.putText(frame, f\"{cf:.2f}\", (int(x1), int(y1)-5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
        "\n",
        "def process_sequence_3videos(seq_dir,\n",
        "                             model_y10, model_y11, model_ssd,\n",
        "                             ground_truth,\n",
        "                             device=\"cpu\",\n",
        "                             conf_thr=0.3,\n",
        "                             iou_thr=0.5,\n",
        "                             person_cls_yolo=0,\n",
        "                             person_cls_ssd=1):\n",
        "    \"\"\"\n",
        "    1) Читаем seqinfo.ini -> FPS\n",
        "    2) Читаем кадры из img1/\n",
        "    3) Для каждого кадра -> запускам 3 модели, рисуем и пишем в 3 отдельные .mp4\n",
        "    4) Сохраняем предсказания в словарях, по завершении считаем метрики (Precision, Recall, F1)\n",
        "    5) Возвращаем словари метрик.\n",
        "    \"\"\"\n",
        "    seq_info = read_seqinfo(seq_dir)\n",
        "    fps = int(seq_info.get('frameRate', 30))\n",
        "\n",
        "    img_folder = os.path.join(seq_dir, 'img1')\n",
        "    if not os.path.exists(img_folder):\n",
        "        print(f\"Папка img1 не найдена в {seq_dir}, пропускаем.\")\n",
        "        return None\n",
        "\n",
        "    frames = sorted([f for f in os.listdir(img_folder) if f.endswith('.jpg')])\n",
        "    if not frames:\n",
        "        print(f\"Нет .jpg кадров в {img_folder}, пропускаем.\")\n",
        "        return None\n",
        "\n",
        "    # Берём первый кадр для инициализации VideoWriter\n",
        "    first_frame_path = os.path.join(img_folder, frames[0])\n",
        "    first_frame = cv2.imread(first_frame_path)\n",
        "    if first_frame is None:\n",
        "        print(\"Не удаётся прочитать первый кадр, пропускаем.\")\n",
        "        return None\n",
        "    h, w, _ = first_frame.shape\n",
        "\n",
        "    # Создаём выходные видеофайлы: YOLOv10, YOLOv11, SSD\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out_y10_path = os.path.join(seq_dir, \"output_yolov10.mp4\")\n",
        "    out_y11_path = os.path.join(seq_dir, \"output_yolov11.mp4\")\n",
        "    out_ssd_path = os.path.join(seq_dir, \"output_ssd.mp4\")\n",
        "\n",
        "    vw_y10 = cv2.VideoWriter(out_y10_path, fourcc, fps, (w, h))\n",
        "    vw_y11 = cv2.VideoWriter(out_y11_path, fourcc, fps, (w, h))\n",
        "    vw_ssd = cv2.VideoWriter(out_ssd_path, fourcc, fps, (w, h))\n",
        "\n",
        "    # Словари для метрик\n",
        "    preds_y10 = {}\n",
        "    preds_y11 = {}\n",
        "    preds_ssd = {}\n",
        "\n",
        "    # Цикл по всем кадрам\n",
        "    for frame_file in tqdm(frames, desc=f\"Обработка {os.path.basename(seq_dir)}\"):\n",
        "        frame_id = int(os.path.splitext(frame_file)[0])  # '000001' -> 1\n",
        "        frame_path = os.path.join(img_folder, frame_file)\n",
        "        frame_bgr = cv2.imread(frame_path)\n",
        "        if frame_bgr is None:\n",
        "            continue\n",
        "\n",
        "        # Детекции\n",
        "        y10_dets = detect_yolo(model_y10, frame_bgr, device=device, conf_thr=conf_thr, person_class=person_cls_yolo)\n",
        "        y11_dets = detect_yolo(model_y11, frame_bgr, device=device, conf_thr=conf_thr, person_class=person_cls_yolo)\n",
        "        ssd_dets = detect_ssd(model_ssd, frame_bgr, device=device, conf_thr=conf_thr, person_class=person_cls_ssd)\n",
        "\n",
        "        # Сохраняем для метрик\n",
        "        preds_y10[frame_id] = y10_dets\n",
        "        preds_y11[frame_id] = y11_dets\n",
        "        preds_ssd[frame_id] = ssd_dets\n",
        "\n",
        "        # Рисуем (каждую модель на своей копии кадра)\n",
        "        f_y10 = frame_bgr.copy()\n",
        "        f_y11 = frame_bgr.copy()\n",
        "        f_ssd = frame_bgr.copy()\n",
        "\n",
        "        draw_boxes_on_frame(f_y10, y10_dets, color=(0,255,0))\n",
        "        draw_boxes_on_frame(f_y11, y11_dets, color=(255,0,0))\n",
        "        draw_boxes_on_frame(f_ssd, ssd_dets, color=(0,0,255))\n",
        "\n",
        "        # Допишем текст о модели\n",
        "        cv2.putText(f_y10, \"YOLOv10\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,0), 2)\n",
        "        cv2.putText(f_y11, \"YOLOv11\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,0,0), 2)\n",
        "        cv2.putText(f_ssd, \"SSD\",     (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 2)\n",
        "\n",
        "        # Записываем в файлы\n",
        "        vw_y10.write(f_y10)\n",
        "        vw_y11.write(f_y11)\n",
        "        vw_ssd.write(f_ssd)\n",
        "\n",
        "    # Закрываем видео\n",
        "    vw_y10.release()\n",
        "    vw_y11.release()\n",
        "    vw_ssd.release()\n",
        "\n",
        "    print(f\"\\nСохранены три видео:\\n  {out_y10_path}\\n  {out_y11_path}\\n  {out_ssd_path}\")\n",
        "\n",
        "    # Подсчёт метрик\n",
        "    metrics_y10 = compute_metrics(preds_y10, ground_truth, iou_thr)\n",
        "    metrics_y11 = compute_metrics(preds_y11, ground_truth, iou_thr)\n",
        "    metrics_ssd = compute_metrics(preds_ssd, ground_truth, iou_thr)\n",
        "\n",
        "    print(\"\\n=== МЕТРИКИ ===\")\n",
        "    print(\"YOLOv10:\", metrics_y10)\n",
        "    print(\"YOLOv11:\", metrics_y11)\n",
        "    print(\"SSD:    \", metrics_ssd)\n",
        "\n",
        "    return metrics_y10, metrics_y11, metrics_ssd\n"
      ],
      "metadata": {
        "id": "w34U2WllfJI8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ЗАПУСК ПО НЕСКОЛЬКИМ ПОСЛЕДОВАТЕЛЬНОСТЯМ MOT"
      ],
      "metadata": {
        "id": "V4bIOb9GzjFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_sequences(base_dir):\n",
        "    \"\"\"\n",
        "    Из списка папок выбираем только уникальные последовательности.\n",
        "    Например: из ['MOT17-01-DPM', 'MOT17-01-FRCNN', 'MOT17-01-SDP']\n",
        "    оставляем только одну (первую по встречаемости).\n",
        "\n",
        "    :param base_dir: путь к директории, где хранятся подпапки.\n",
        "    :return: список уникальных путей к папкам.\n",
        "    \"\"\"\n",
        "    all_subdirs = sorted(os.listdir(base_dir))\n",
        "    unique_sequences = {}\n",
        "\n",
        "    for folder in all_subdirs:\n",
        "        # Разделяем название папки по символу '-'\n",
        "        parts = folder.split('-')\n",
        "        if len(parts) < 2:\n",
        "            continue  # Пропускаем, если имя папки не соответствует формату\n",
        "\n",
        "        # Основная часть последовательности, например 'MOT17-01'\n",
        "        base_sequence = '-'.join(parts[:2])\n",
        "\n",
        "        # Если базовая последовательность ещё не добавлена, добавляем её\n",
        "        if base_sequence not in unique_sequences:\n",
        "            unique_sequences[base_sequence] = os.path.join(base_dir, folder)\n",
        "\n",
        "    return list(unique_sequences.values())\n",
        "\n",
        "# Основной код запуска\n",
        "base_dir = \"MOT17/MOT17/train\"  # train, т.к. там есть GT-файлы (в MOT17 test их нет), чтобы можно было оценить точность\n",
        "\n",
        "# Выбираем только уникальные последовательности\n",
        "unique_dirs = get_unique_sequences(base_dir)\n",
        "\n",
        "for seq_path in unique_dirs:\n",
        "    seq_name = os.path.basename(seq_path)\n",
        "\n",
        "    # Проверяем наличие gt/gt.txt\n",
        "    gt_path = os.path.join(seq_path, 'gt', 'gt.txt')\n",
        "    if not os.path.exists(gt_path):\n",
        "        print(f\"{seq_name}: нет GT (gt.txt), пропускаем расчёт метрик.\")\n",
        "        continue\n",
        "\n",
        "    # Читаем GT\n",
        "    ground_truth = read_ground_truth(gt_path)\n",
        "    if not ground_truth:\n",
        "        print(f\"{seq_name}: нет объектов class=1 в GT, пропускаем.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n=== Обрабатываем последовательность: {seq_name} ===\")\n",
        "\n",
        "    print(\"Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\")\n",
        "    metrics_y10, metrics_y11, metrics_ssd = process_sequence_3videos(\n",
        "        seq_dir=seq_path,\n",
        "        model_y10=model_y10,\n",
        "        model_y11=model_y11,\n",
        "        model_ssd=model_ssd,\n",
        "        ground_truth=ground_truth,\n",
        "        device=device,\n",
        "        conf_thr=0.3,\n",
        "        iou_thr=0.5,\n",
        "        person_cls_yolo=yolo_person_cls,\n",
        "        person_cls_ssd=ssd_person_cls\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys_ugUSdfL0c",
        "outputId": "4ce8f6c2-8210-4ddd-e9b0-39762bc507f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Обрабатываем последовательность: MOT17-02-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-02-DPM: 100%|██████████| 600/600 [02:05<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-02-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-02-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-02-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.8905511811023622, 'recall': 0.18260588773478284, 'f1': 0.303068197043455}\n",
            "YOLOv11: {'precision': 0.8448857994041709, 'recall': 0.22894354448092138, 'f1': 0.3602642276422764}\n",
            "SSD:     {'precision': 0.6699612403100775, 'recall': 0.18605026640116248, 'f1': 0.29122614885640874}\n",
            "\n",
            "=== Обрабатываем последовательность: MOT17-04-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-04-DPM: 100%|██████████| 1050/1050 [03:30<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-04-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-04-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-04-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.9308847134359362, 'recall': 0.20730912378829616, 'f1': 0.33910022700694775}\n",
            "YOLOv11: {'precision': 0.9362198599948146, 'recall': 0.30371974683011965, 'f1': 0.4586488846550766}\n",
            "SSD:     {'precision': 0.8483718617946806, 'recall': 0.14353302352965916, 'f1': 0.245526320522274}\n",
            "\n",
            "=== Обрабатываем последовательность: MOT17-05-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-05-DPM: 100%|██████████| 837/837 [01:10<00:00, 11.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-05-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-05-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-05-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.8434764909423977, 'recall': 0.5991036576550528, 'f1': 0.7005917159763314}\n",
            "YOLOv11: {'precision': 0.8034958601655934, 'recall': 0.6313430678039612, 'f1': 0.7070919689119171}\n",
            "SSD:     {'precision': 0.854873132558691, 'recall': 0.5211797021830273, 'f1': 0.647566014011137}\n",
            "\n",
            "=== Обрабатываем последовательность: MOT17-09-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-09-DPM: 100%|██████████| 525/525 [01:45<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-09-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-09-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-09-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.8682441516536703, 'recall': 0.6063849765258216, 'f1': 0.7140645731977002}\n",
            "YOLOv11: {'precision': 0.7702327567798419, 'recall': 0.6773708920187793, 'f1': 0.7208233413269384}\n",
            "SSD:     {'precision': 0.8636200071968334, 'recall': 0.4507042253521127, 'f1': 0.5923000987166831}\n",
            "\n",
            "=== Обрабатываем последовательность: MOT17-10-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-10-DPM: 100%|██████████| 654/654 [02:10<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-10-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-10-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-10-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.867871259175607, 'recall': 0.3591401199470364, 'f1': 0.5080431908329661}\n",
            "YOLOv11: {'precision': 0.8181818181818182, 'recall': 0.40727470986836983, 'f1': 0.5438377535101404}\n",
            "SSD:     {'precision': 0.7541387024608501, 'recall': 0.2625593893605421, 'f1': 0.3895083482581316}\n",
            "\n",
            "=== Обрабатываем последовательность: MOT17-11-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-11-DPM: 100%|██████████| 900/900 [03:05<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-11-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-11-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-11-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.903842954583264, 'recall': 0.5757736328952946, 'f1': 0.7034375606913964}\n",
            "YOLOv11: {'precision': 0.8698207021244538, 'recall': 0.6118058499364137, 'f1': 0.7183475393517078}\n",
            "SSD:     {'precision': 0.8831644751023927, 'recall': 0.43418821534548535, 'f1': 0.5821669626998224}\n",
            "\n",
            "=== Обрабатываем последовательность: MOT17-13-DPM ===\n",
            "Создаём 3 видео (YOLOv10 / YOLOv11 / SSD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка MOT17-13-DPM: 100%|██████████| 750/750 [02:25<00:00,  5.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сохранены три видео:\n",
            "  MOT17/MOT17/train/MOT17-13-DPM/output_yolov10.mp4\n",
            "  MOT17/MOT17/train/MOT17-13-DPM/output_yolov11.mp4\n",
            "  MOT17/MOT17/train/MOT17-13-DPM/output_ssd.mp4\n",
            "\n",
            "=== МЕТРИКИ ===\n",
            "YOLOv10: {'precision': 0.8936800526662277, 'recall': 0.23320735268854148, 'f1': 0.3698910081743869}\n",
            "YOLOv11: {'precision': 0.8821476510067114, 'recall': 0.282253908263185, 'f1': 0.4276696817856446}\n",
            "SSD:     {'precision': 0.6820877817319099, 'recall': 0.1481704174540457, 'f1': 0.24345494319384658}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Общие наблюдения:**\n",
        "\n",
        "* **YOLOv11** в большинстве случаев показывает **наилучший баланс между точностью (Precision) и полнотой (Recall)**, что отражается в более высоких значениях F1-меры.\n",
        "* **YOLOv10** демонстрирует **высокую точность (Precision)**, но часто **уступает YOLOv11 в полноте (Recall)**, что говорит о том, что он может пропускать часть объектов.\n",
        "* **SSD** обычно показывает **более низкие значения Recall** по сравнению с YOLO моделями, что указывает на большее количество пропущенных объектов. Его точность (Precision) варьируется, иногда приближаясь к YOLO, но часто остаётся ниже.\n",
        "\n",
        "* **Точность (Precision):** Обе YOLO модели демонстрируют высокую точность, с небольшим преимуществом у YOLOv10. Это означает, что когда они детектируют объект, вероятность того, что это действительно человек, высока. SSD показывает несколько более низкую точность.\n",
        "* **Полнота (Recall):** YOLOv11 обычно имеет более высокую полноту, чем YOLOv10 и SSD. Это означает, что YOLOv11 лучше справляется с обнаружением всех присутствующих людей в кадре. SSD показывает наименьшую полноту, что говорит о большем количестве пропущенных обнаружений.\n",
        "* **F1-мера:**  F1-мера, которая является гармоническим средним между Precision и Recall, показывает, что **YOLOv11 в среднем обеспечивает лучший баланс** между этими двумя метриками. YOLOv10 занимает второе место, а SSD показывает наименьшее значение F1.\n",
        "\n",
        "**Различия в результатах на разных видеопоследовательностях:**\n",
        "\n",
        "Наблюдается **зависимость производительности моделей от конкретной видеопоследовательности**. Например, на последовательности `MOT17-05-DPM` все три модели показали относительно высокие значения Recall и F1, в то время как на других последовательностях, таких как `MOT17-02-DPM` и `MOT17-04-DPM`, Recall был значительно ниже. Это может быть связано с различными условиями съемки, плотностью людей, освещением и т.д.\n",
        "\n",
        "**Качество детектирования на видео:**\n",
        "\n",
        "На основе визуального анализа созданных видеороликов можно отметить следующее:\n",
        "\n",
        "* **YOLO модели** в целом **более уверенно детектируют людей**, выделяя их более точно и с меньшим количеством ложных срабатываний, особенно при хорошем освещении и четкой видимости.\n",
        "* **SSD** иногда **пропускает объекты** или **выделяет их менее точно**, особенно в случаях, когда люди находятся на некотором расстоянии или частично перекрыты другими объектами.\n",
        "\n",
        "**Выводы:**\n",
        "\n",
        "* **YOLOv11 представляется наиболее сбалансированной моделью** для задачи детекции людей в видеопотоке, обеспечивая хорошее сочетание точности и полноты.\n",
        "* **YOLOv10** может быть предпочтительнее в сценариях, где **важнее минимизировать ложные срабатывания**, даже ценой пропуска некоторых объектов.\n",
        "* **SSD** в текущей конфигурации **уступает YOLO моделям по качеству детекции** на данном наборе данных, особенно в плане полноты обнаружения.\n"
      ],
      "metadata": {
        "id": "JN5thhTQUOuD"
      }
    }
  ]
}